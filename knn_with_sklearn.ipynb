{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "#  K-Nearest Neighbors with Scikit-Learn\n",
    "\n",
    "_Authors: Alex Sherman (DC)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "## Learning Objectives\n",
    "\n",
    "1. Utilize KNN model on iris dataset\n",
    "2. Implement SKLearn KNN model\n",
    "3. Assess fit KNN Model using SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Learning Objectives](#learning-objectives)\n",
    "- [Overview of the iris dataset](#overview-of-the-iris-dataset)\n",
    "\t- [Terminology](#terminology)\n",
    "- [Exercise: \"Human learning\" with iris data](#exercise-human-learning-with-iris-data)\n",
    "- [Human learning on the iris dataset](#human-learning-on-the-iris-dataset)\n",
    "- [K-nearest neighbors (KNN) classification](#k-nearest-neighbors-knn-classification)\n",
    "\t- [Using the train/test split procedure (K=1)](#using-the-traintest-split-procedure-k)\n",
    "- [Tuning a KNN model](#tuning-a-knn-model)\n",
    "\t- [What happen if we view the accuracy of our training data?](#what-happen-if-we-view-the-accuracy-of-our-training-data)\n",
    "\t- [Training error versus testing error](#training-error-versus-testing-error)\n",
    "- [Standardizing features](#standardizing-features)\n",
    "\t- [Use StandardScaler to standardize our data.](#use-standardscaler-to-standardize-our-data)\n",
    "- [Comparing KNN with other models](#comparing-knn-with-other-models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview-of-the-iris-dataset\"></a>\n",
    "## Overview of the iris dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the iris data into a DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = './assets/dataset/iris.data'\n",
    "iris = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terminology\"></a>\n",
    "### Terminology\n",
    "\n",
    "- **150 observations** (n=150): each observation is one iris flower\n",
    "- **4 features** (p=4): sepal length, sepal width, petal length, and petal width\n",
    "- **Response**: iris species\n",
    "- **Classification problem** since response is categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"exercise-human-learning-with-iris-data\"></a>\n",
    "## Exercise: \"Human learning\" with iris data\n",
    "\n",
    "**Question:** Can you predict the species of an iris using petal and sepal measurements?\n",
    "\n",
    "1. Read the iris data into a Pandas DataFrame, including column names.\n",
    "2. Gather some basic information about the data.\n",
    "3. Use sorting, split-apply-combine, and/or visualization to look for differences between species.\n",
    "4. Write down a set of rules that could be used to predict species based on iris measurements.\n",
    "\n",
    "**BONUS:** Define a function that accepts a row of data and returns a predicted species. Then, use that function to make predictions for all existing rows of data, and check the accuracy of your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# increase default figure and font sizes for easier viewing\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Read the iris data into a pandas DataFrame, including column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the URL from which to retrieve the data (as a string)\n",
    "path = './assets/dataset/iris.data'\n",
    "\n",
    "# retrieve the CSV file and add the column names\n",
    "iris = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Gather some basic information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# observe first five rows of data\n",
    "iris.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Use sorting, split-apply-combine, and/or visualization to look for differences between species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort the DataFrame by petal_width\n",
    "iris.sort_values(by='petal_width', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort the DataFrame by petal_width and display the NumPy array\n",
    "iris.sort_values(by='petal_width', ascending=True).values[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Split-apply-combine: Explore the data while using a groupby on 'species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean of sepal_length grouped by species\n",
    "iris.groupby(by='species', axis=0).sepal_length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean of all numeric columns grouped by species\n",
    "iris.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# description of all numeric columns grouped by species\n",
    "iris.groupby('species').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# description of all numeric columns grouped by species\n",
    "iris.groupby('species').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# box plot of petal_width grouped by species\n",
    "iris.boxplot(column='petal_width', by='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# box plot of all numeric columns grouped by species\n",
    "iris.boxplot(by='species', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map species to a numeric value so that plots can be colored by species\n",
    "iris['species_num'] = iris.species.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "\n",
    "# alternative method\n",
    "iris['species_num'] = iris.species.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter plot of petal_length vs petal_width colored by species\n",
    "iris.plot(kind='scatter', x='petal_length', y='petal_width', c='species_num', colormap='brg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter matrix of all features colored by species\n",
    "pd.scatter_matrix(iris.drop('species_num', axis=1), c=iris.species_num, figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Write down a set of rules that could be used to predict species based on iris measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a new feature that represents petal area (\"feature engineering\")\n",
    "# since iris petals are more ovular shaped as opposed to rectangular\n",
    "# we're going to use the formula for area of an ellipse\n",
    "# r1 * r2 * 3.14\n",
    "iris['petal_area'] = ((iris.petal_length/2) * (iris.petal_width/2) * 3.124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# description of petal_area grouped by species\n",
    "iris.groupby('species').petal_area.describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# box plot of petal_area grouped by species\n",
    "iris.boxplot(column='petal_area', by='species',figsize=(5,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only show irises with a petal_area between 3 and 7\n",
    "iris[(iris.petal_area > 3) & (iris.petal_area < 7)].sort_values('petal_area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "My set of rules for predicting species:\n",
    "\n",
    "- If petal_area is less than 2, predict **setosa**.\n",
    "- Else if petal_area is less than 7.4, predict **versicolor**.\n",
    "- Otherwise, predict **virginica**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Bonus: Define a function that accepts a row of data and returns a predicted species. Then, use that function to make predictions for all existing rows of data, and check the accuracy of your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_a,val_b = ('a','b')\n",
    "val_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_flower(df):\n",
    "    preds = []\n",
    "    for ind, row in df.iterrows():        \n",
    "        if row.petal_area < 2:\n",
    "            prediction = 'Iris-setosa'\n",
    "        elif row.petal_area < 7.4:\n",
    "            prediction = 'Iris-versicolor'\n",
    "        else:\n",
    "            prediction = 'Iris-virginica'\n",
    "        preds.append(prediction)\n",
    "    \n",
    "    df['prediction'] = preds   \n",
    "    \n",
    "    \n",
    "predict_flower(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(iris.species == iris.prediction) / 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"human-learning-on-the-iris-dataset\"></a>\n",
    "## Human learning on the iris dataset\n",
    "---\n",
    "\n",
    "How did we (as humans) predict the species of an iris?\n",
    "\n",
    "1. We observed that the different species had (somewhat) dissimilar measurements.\n",
    "2. We focused on features that seemed to correlate with the response.\n",
    "3. We created a set of rules (using those features) to predict the species of an unknown iris.\n",
    "\n",
    "We assumed that if an **unknown iris** has measurements similar to **previous irises**, then its species is most likely the same as those previous irises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# increase default figure and font sizes for easier viewing\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# create a custom colormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map each iris species to a number\n",
    "iris['species_num'] = iris.species.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# box plot of all numeric columns grouped by species\n",
    "iris.drop('species_num', axis=1).boxplot(by='species', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a scatter plot of PETAL LENGTH versus PETAL WIDTH and color by SPECIES\n",
    "iris.plot(kind='scatter', x='petal_length', y='petal_width', c='species_num', colormap=cmap_bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris['pred_num'] = iris.prediction.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "\n",
    "\n",
    "\n",
    "# create a scatter plot of PETAL LENGTH versus PETAL WIDTH and color by PREDICTION\n",
    "iris.plot(kind='scatter', x='petal_length', y='petal_width', c='pred_num', colormap=cmap_bold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"k-nearest-neighbors-knn-classification\"></a>\n",
    "## K-nearest neighbors (KNN) classification\n",
    "---\n",
    "\n",
    "K Nearest Classification is (as its name implies) a classification model that uses the 'K' most similar observations in order to make a prediction.\n",
    "\n",
    "KNN is a supervised learning method therefore the 'K' most similar observations must have a known target value.\n",
    "\n",
    "The process of of prediction using KNN is fairly straight forward.\n",
    "\n",
    "1. Pick a value for K.\n",
    "2. Search for the K observations in the data that are \"nearest\" to the measurements of the unknown iris.\n",
    "    - Euclidian distance is often used as the distance metric, but other metrics are allowed.\n",
    "3. Use the most popular response value from the K \"nearest neighbors\" as the predicted response value for the unknown iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below visualizations show how a given area can change in its prediction as K changes.  Colored points represent true values and colored aread represents a prediction space, in that if an unknown point was to fall in a space its predicted value would be the color of that scace it is in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"knn-classification-map-for-iris-k\"></a>\n",
    "### KNN classification map for iris (K=1)\n",
    "\n",
    "![1NN classification map](./assets/images/iris_01nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map for iris (K=5)\n",
    "\n",
    "![5NN classification map](./assets/images/iris_05nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map for iris (K=15)\n",
    "\n",
    "![15NN classification map](./assets/images/iris_15nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"knn-classification-map-for-iris-k\"></a>\n",
    "### KNN classification map for iris (K=50)\n",
    "\n",
    "![50NN classification map](./assets/images/iris_50nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as more Ks are added, the classification spaces boarders become more distinct, however you can see that the spaces are not perfectly pure as far as the known elements within them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What's the \"best\" value for K in this case?\n",
    "\n",
    "**Answer:** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the NBA data into a DataFrame\n",
    "import pandas as pd\n",
    "path = './assets/dataset/NBA_players_2015.csv'\n",
    "nba = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map positions to numbers\n",
    "nba['pos_num'] = nba.pos.map({'C':0, 'F':1, 'G':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create feature matrix (X)\n",
    "feature_cols = ['ast', 'stl', 'blk', 'tov', 'pf']\n",
    "X = nba[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create response vector (y)\n",
    "y = nba.pos_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"using-the-traintest-split-procedure-k\"></a>\n",
    "### Using the train/test split procedure (K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1: split X and y into training and testing sets (using random_state for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2: train the model on the training set (using K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3: test the model on the testing set, and check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_class = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Repeating for K=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Comparing testing accuracy with null accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Null accuracy is the accuracy that could be achieved by **always predicting the most frequent class**. It is a benchmark against which you may want to measure your classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### examine the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tuning-a-knn-model\"></a>\n",
    "## Tuning a KNN model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model (using the value K=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model with data\n",
    "knn.fit(X, y)\n",
    "\n",
    "# store the predicted response values\n",
    "y_pred_class = knn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which model produced the correct predictions for the two unknown irises?\n",
    "\n",
    "**Answer:** ...\n",
    "\n",
    "**Question:** Does that mean that we have to guess how well our models are likely to do?\n",
    "\n",
    "**Answer:** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities of class membership\n",
    "knn.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-happen-if-we-view-the-accuracy-of-our-training-data\"></a>\n",
    "### What happen if we view the accuracy of our training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1,100):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X,y)\n",
    "    pred = knn.predict(X)\n",
    "    score = float(sum(pred == y)) / len(y)\n",
    "    scores.append([k, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(scores,columns=['k','score'])\n",
    "data.plot.line(x='k',y='score')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Searching for the \"best\" value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate TRAINING ERROR and TESTING ERROR for K=1 through 100\n",
    "\n",
    "k_range = range(1, 101)\n",
    "training_error = []\n",
    "testing_error = []\n",
    "\n",
    "for k in k_range:\n",
    "\n",
    "    # instantiate the model with the current K value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # calculate training error\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_class = knn.predict(X)\n",
    "    training_accuracy = metrics.accuracy_score(y, y_pred_class)\n",
    "    training_error.append(1 - training_accuracy)\n",
    "    \n",
    "    # calculate testing error\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_class = knn.predict(X_test)\n",
    "    testing_accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    testing_error.append(1 - testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of K, training error, and testing error\n",
    "column_dict = {'K': k_range, 'training error':training_error, 'testing error':testing_error}\n",
    "df = pd.DataFrame(column_dict).set_index('K').sort_index(ascending=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the relationship between K (HIGH TO LOW) and TESTING ERROR\n",
    "df.plot(y='testing error')\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Error (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the minimum testing error and the associated K value\n",
    "df.sort_values('testing error').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternative method\n",
    "min(zip(testing_error, k_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training-error-versus-testing-error\"></a>\n",
    "### Training error versus testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the relationship between K (HIGH TO LOW) and both TRAINING ERROR and TESTING ERROR\n",
    "df.plot()\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Error (lower is better)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Training error** decreases as model complexity increases (lower value of K)\n",
    "- **Testing error** is minimized at the optimum model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Making predictions on out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Given the statistics of a (truly) unknown player, how do we predict his position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# instantiate the model with the best known parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=14)\n",
    "\n",
    "# re-train the model with X and y (not X_train and y_train) - why?\n",
    "knn.fit(X, y)\n",
    "\n",
    "# make a prediction for an out-of-sample observation\n",
    "knn.predict(np.array([2, 1, 0, 1, 2]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What could we conclude?\n",
    "\n",
    "- When using KNN on this dataset with these features, the **best value for K** is likely to be around 14.\n",
    "- Given the statistics of an **unknown player**, we estimate that we would be able to correctly predict his position about 74% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"standardizing-features\"></a>\n",
    "## Standardizing features\n",
    "---\n",
    "\n",
    "There is one major issue that applies to most machine learning models. They are sensitive to feature scale.\n",
    "\n",
    "This means that it matters whether out feature are centered around zero and have similar variance to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of KNN on the Iris data set, image we measure sepal length in kilometers, but sepal width in millimeters. Our data will show variation in sepal width, but almost no variation in sepal length.\n",
    "\n",
    "Unfortunately, KNN cannot automatically adjust to this. Other models tend to struggle with scale as well, even linear regression when you get into more advanced methods such as regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortuantely, this is an easy fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"use-standardscaler-to-standardize-our-data\"></a>\n",
    "### Use StandardScaler to standardize our data.\n",
    "\n",
    "StandardScaler standardizes our data by subtracting the mean from each feature and dividing by it's standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seperate feature matrix and response for sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create feature matrix (X)\n",
    "feature_cols = ['ast', 'stl', 'blk', 'tov', 'pf']\n",
    "X = nba[feature_cols]\n",
    "# create response vector (y)\n",
    "y = nba.pos_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train-test-split.\n",
    "\n",
    "Notice that we create the train-test-split first. This is because we will reveal information about our testing data if we standardize right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Instantiate and fit standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a KNN model and look at the testing error.\n",
    "Can you find a number of neighbors that improves our results from before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate testing error\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "testing_accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "testing_error = 1 - testing_accuracy\n",
    "print testing_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-knn-with-other-models\"></a>\n",
    "## Comparing KNN with other models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of KNN:**\n",
    "\n",
    "- Simple to understand and explain\n",
    "- Model training is fast\n",
    "- Can be used for classification and regression\n",
    "- Being a non-parametric method, it is often successful in classification situations where the decision boundary is very irregular\n",
    "\n",
    "**Disadvantages of KNN:**\n",
    "\n",
    "- Must store all of the training data\n",
    "- Prediction phase can be slow when n is large\n",
    "- Sensitive to irrelevant features\n",
    "- Sensitive to the scale of the data\n",
    "- Accuracy is (generally) not competitive with the best supervised learning methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
